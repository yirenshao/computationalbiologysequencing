{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "# Get k-mers from a sequence\n",
    "\n",
    "\n",
    "def get_kmers(sequence, k):\n",
    "    return [sequence[x:x+k] for x in range(len(sequence) - k + 1)]\n",
    "\n",
    "# Get the frequency of each k-mer in a sequence\n",
    "\n",
    "\n",
    "def freq_kmers(seq, k):\n",
    "    kmers = get_kmers(seq, k)\n",
    "    freq = {}\n",
    "    for kmer in kmers:\n",
    "        if kmer not in freq:\n",
    "            freq[kmer] = 1\n",
    "        else:\n",
    "            freq[kmer] += 1\n",
    "    return freq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Spectrum Kernel\n",
    "def spectrum_kernel(seq1, seq2, k):\n",
    "    possiblekmers = kmers_generator(k)\n",
    "    freq1 = freq_kmers(seq1, k)\n",
    "    freq2 = freq_kmers(seq2, k)\n",
    "    for key in possiblekmers:\n",
    "        if key not in freq1:\n",
    "            freq1[key] = 0\n",
    "        if key not in freq2:\n",
    "            freq2[key] = 0\n",
    "            \n",
    "    freq1_lst = [freq1[key] for key in possiblekmers]\n",
    "    freq2_lst = [freq2[key] for key in possiblekmers]\n",
    "    similarity = np.dot([freq1[key] for key in possiblekmers], [freq2[key] for key in possiblekmers])\n",
    "    normalization = math.sqrt(np.dot([freq1[key] for key in freq1],[freq1[key] for key in freq1])) *  math.sqrt(np.dot([freq2[key] for key in freq1],[freq2[key] for key in freq1]))\n",
    "    # freq1 = {k: v for k, v in sorted(freq1.items(), key=lambda item: item[1], reverse=True)}\n",
    "    # freq2 = {k: v for k, v in sorted(freq2.items(), key=lambda item: item[1], reverse=True)}\n",
    "    #similarity = similarity/normalization\n",
    "    return similarity, freq1_lst, freq2_lst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change fasta file into a list of sequences\n",
    "# fasta reader\n",
    "def read_fasta(file):\n",
    "    with open(file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    return lines\n",
    "\n",
    "# fasta parser\n",
    "\n",
    "\n",
    "def parse_fasta(lines):\n",
    "    seq_list = []\n",
    "    seq_name = [line for line in lines if line.startswith('>')]\n",
    "    seq = ''\n",
    "    for line, index in zip(lines, range(len(lines))):\n",
    "        if index == len(lines) - 1:\n",
    "            seq += line.strip()\n",
    "            seq_list.append(seq)\n",
    "        if line.startswith('>'):\n",
    "            seq_list.append(seq)\n",
    "            seq = ''\n",
    "            continue\n",
    "        else:\n",
    "            seq += line.strip()\n",
    "    for i in seq_list:\n",
    "        if i == '':\n",
    "            seq_list.remove(i)\n",
    "    return seq_list, seq_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './kmeans/kmeans.fasta'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[184], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m seq, seq_name \u001b[38;5;241m=\u001b[39m parse_fasta(\u001b[43mread_fasta\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./kmeans/kmeans.fasta\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# print(spectrum_kernel(seq1, seq2, 3))\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(seq_name)\n",
      "Cell \u001b[0;32mIn[183], line 4\u001b[0m, in \u001b[0;36mread_fasta\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_fasta\u001b[39m(file):\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      5\u001b[0m         lines \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mreadlines()\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lines\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.10/site-packages/IPython/core/interactiveshell.py?line=274'>275</a>\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.10/site-packages/IPython/core/interactiveshell.py?line=275'>276</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.10/site-packages/IPython/core/interactiveshell.py?line=276'>277</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.10/site-packages/IPython/core/interactiveshell.py?line=277'>278</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.10/site-packages/IPython/core/interactiveshell.py?line=278'>279</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.10/site-packages/IPython/core/interactiveshell.py?line=279'>280</a>\u001b[0m     )\n\u001b[0;32m--> <a href='file:///usr/local/lib/python3.10/site-packages/IPython/core/interactiveshell.py?line=281'>282</a>\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './kmeans/kmeans.fasta'"
     ]
    }
   ],
   "source": [
    "seq, seq_name = parse_fasta(read_fasta('./kmeans/kmeans.fasta'))\n",
    "# print(spectrum_kernel(seq1, seq2, 3))\n",
    "print(seq_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "seq1 = \"AATCCG\"\n",
    "seq2 = \"AATGCC\"\n",
    "print(spectrum_kernel(seq1, seq2, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "def dist(seq1, seq2, k):\n",
    "    return np.sqrt(spectrum_kernel(seq1, seq1, k)-2*spectrum_kernel(seq1, seq2, k)+spectrum_kernel(seq2, seq2, k))\n",
    "\n",
    "\n",
    "def KNN(train, test, knn_num, kmer_size):\n",
    "    seq_train = []\n",
    "    seq_name_train = []\n",
    "    for path in train:\n",
    "        seq, seq_name = parse_fasta(read_fasta(path))\n",
    "        seq_train += seq\n",
    "        seq_name_train += seq_name\n",
    "    seq_test, seq_name_test = parse_fasta(read_fasta(test))\n",
    "    train_class_list = [\"exons\" if \"exon\" in seq_name_train[i]\n",
    "                        else \"introns\" for i in range(len(seq_name_train))]\n",
    "    test_true_class_list = [\"exons\" if \"exon\" in seq_name_test[i]\n",
    "                            else \"introns\" for i in range(len(seq_name_test))]\n",
    "    test_pred_class_list = []\n",
    "    for i in range(len(seq_test)):\n",
    "        dist_list = []\n",
    "        for j in range(len(seq_train)):\n",
    "            dist_list.append(dist(seq_test[i], seq_train[j], kmer_size))\n",
    "        dist_list = np.array(dist_list)\n",
    "        indexes = np.argsort(dist_list)\n",
    "        exons_num = 0\n",
    "        introns_num = 0\n",
    "        for index in indexes[:knn_num]:\n",
    "            if train_class_list[index] == \"exons\":\n",
    "                exons_num += 1\n",
    "            else:\n",
    "                introns_num += 1\n",
    "        if exons_num > introns_num:\n",
    "            test_pred_class_list.append(\"exons\")\n",
    "        else:\n",
    "            test_pred_class_list.append(\"introns\")\n",
    "    correct = 0\n",
    "    for i, j in zip(test_true_class_list, test_pred_class_list):\n",
    "        if i == j:\n",
    "            correct += 1\n",
    "\n",
    "    accuracy = correct/len(test_true_class_list)\n",
    "\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97375"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN(train=[\"./KNN/train-exons100.fasta\", \"./KNN/train-introns100.fasta\"],\n",
    "    test=\"./KNN/test.fasta\", knn_num=5, kmer_size=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change fasta file into a list of sequences\n",
    "# fasta reader\n",
    "def read_fasta(file):\n",
    "    with open(file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    return lines\n",
    "\n",
    "# fasta parser\n",
    "\n",
    "\n",
    "def parse_fasta(lines):\n",
    "    seq_list = []\n",
    "    seq = ''\n",
    "    seq_name = []\n",
    "    for line, index in zip(lines, range(len(lines))):\n",
    "        if index == len(lines) - 1:\n",
    "            seq += line.strip()\n",
    "            seq_list.append(seq)\n",
    "        if line.startswith('>'):\n",
    "            seq_list.append(seq)\n",
    "            seq = ''\n",
    "            name = line.strip()\n",
    "            seq_name.append(name.split(\" /\")[0][1:])\n",
    "            continue\n",
    "        else:\n",
    "            seq += line.strip()\n",
    "    for i in seq_list:\n",
    "        if i == '':\n",
    "            seq_list.remove(i)\n",
    "    return seq_list, seq_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff(key1, key2):\n",
    "    list1 = list(key1)\n",
    "    list2 = list(key2)\n",
    "    dif = 0\n",
    "    for i in range(len(list1)):\n",
    "        if list1[i] != list2[i]:\n",
    "            dif += 1\n",
    "    return dif\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KMEANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mismatch_kmers(kmer):\n",
    "    bases = ['A', 'C', 'G', 'T']\n",
    "    mismatches = []\n",
    "    for i in range(len(kmer)):\n",
    "        for b in bases:\n",
    "            if b != kmer[i]:\n",
    "                new_kmer = kmer[:i] + b + kmer[i+1:]\n",
    "                mismatches.append(new_kmer)\n",
    "    return mismatches\n",
    "def kmers_generator(k):\n",
    "    bases = ['A', 'C', 'G', 'T']\n",
    "    kmers = []\n",
    "    for i in range(k):\n",
    "        if i == 0:\n",
    "            kmers = bases\n",
    "        else:\n",
    "            kmers = [kmer + b for kmer in kmers for b in bases]\n",
    "    return kmers\n",
    "\n",
    "\n",
    "def count_kmer(seq, kmer):\n",
    "    count = 0\n",
    "    k = len(kmer)\n",
    "    for i in range(len(seq) - k + 1):\n",
    "        if seq[i:i+k] == kmer:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def mismatch_freq_kmers(seq, k):\n",
    "    kmers = kmers_generator(k)\n",
    "    freq = {}\n",
    "    # count all kmers\n",
    "    for kmer in kmers:\n",
    "        freq[kmer] = count_kmer(seq, kmer)\n",
    "    # count all mismatch kmers\n",
    "    for i in range(len(seq) - k + 1):\n",
    "        mismatch_kmers = generate_mismatch_kmers(seq[i:i+k])\n",
    "        for mismatch_kmer in mismatch_kmers:\n",
    "                freq[mismatch_kmer] += 1\n",
    "    return freq\n",
    "\n",
    "def mismatch_spectrum_kernel(seq1, seq2, k):\n",
    "    freq1 = mismatch_freq_kmers(seq1, k)\n",
    "    freq2 = mismatch_freq_kmers(seq2, k)\n",
    "    for key in freq1:\n",
    "        if key not in freq2:\n",
    "            freq2[key] = 0\n",
    "    for key in freq2:\n",
    "        if key not in freq1:\n",
    "            freq1[key] = 0\n",
    "    freq1_lst = [freq1[key] for key in freq1]\n",
    "    freq2_lst = [freq2[key] for key in freq1]\n",
    "    similarity = np.dot(freq1_lst, freq2_lst)\n",
    "    normalization = math.sqrt(np.dot(freq1_lst, freq1_lst)) * math.sqrt(np.dot(freq2_lst, freq2_lst))\n",
    "    \n",
    "\n",
    "    return similarity, freq1_lst, freq2_lst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(kmers_generator(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans(seqpath, ncluster, kmer_size, maxniter, distfunc):\n",
    "    seq_list, seq_names = parse_fasta(read_fasta(seqpath))\n",
    "    centroids = np.random.randint(0, len(seq_list), ncluster)\n",
    "    # initialize class_list\n",
    "    class_list = {}\n",
    "    seq_kernel_list = []\n",
    "    for seq in seq_list:\n",
    "        similarity_list = []\n",
    "        for centroid in centroids:\n",
    "            similarity, seq_spectrum, centroid_spectrum = distfunc(\n",
    "                seq, seq_list[centroid], kmer_size)\n",
    "            similarity = np.dot(centroid_spectrum,centroid_spectrum) + np.dot(seq_spectrum,seq_spectrum) - 2 * similarity\n",
    "            seq_kernel_list.append(seq_spectrum)\n",
    "            similarity_list.append(similarity)\n",
    "\n",
    "        class_list[seq] = np.argmin(np.array(similarity_list))\n",
    "    # update centroids 1st time\n",
    "    centroids = []\n",
    "    for i in range(ncluster):\n",
    "        tmp_list = []\n",
    "        for seq, seq_kernel in zip(seq_list, seq_kernel_list):\n",
    "            if class_list[seq] == i:\n",
    "                tmp_list.append(seq_kernel)\n",
    "        centroids.append(np.mean(tmp_list, axis=0))\n",
    "    centroids_new = centroids.copy()\n",
    "    old_class_list = class_list.copy()\n",
    "    for i in range(maxniter):\n",
    "        # update class_list\n",
    "        for seq, seq_kernel in zip(seq_list, seq_kernel_list):\n",
    "            similarity_list = []\n",
    "            for centroid in centroids_new:\n",
    "                similarity = np.dot(seq_kernel, centroid)\n",
    "                similarity = np.dot(centroid_spectrum,centroid_spectrum) + np.dot(seq_spectrum,seq_spectrum) - 2 * similarity\n",
    "                similarity_list.append(similarity)\n",
    "            class_list[seq] = np.argmin(np.array(similarity_list))\n",
    "        if class_list == old_class_list:\n",
    "            break\n",
    "        old_class_list = class_list.copy()\n",
    "        # update centroids\n",
    "        centroids_new = []\n",
    "        for i in range(ncluster):\n",
    "            tmp_list = []\n",
    "            for seq, seq_kernel in zip(seq_list, seq_kernel_list):\n",
    "                if class_list[seq] == i:\n",
    "                    tmp_list.append(seq_kernel)\n",
    "            centroids_new.append(np.mean(tmp_list, axis=0))\n",
    "\n",
    "    return centroids_new, class_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqpath = \"kmeans.fasta\"\n",
    "#centroids, class_list = kmeans(seqspath, 3, 6, 100, mismatch_spectrum_kernel)\n",
    "# centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_list, seq_names = parse_fasta(read_fasta(seqspath))\n",
    "ncluster = 2\n",
    "kmer_size = 6\n",
    "maxniter = 100\n",
    "centroids, class_list = kmeans(seqpath, ncluster, kmer_size, maxniter, mismatch_spectrum_kernel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printtest(seq_list,seq_names,class_list,kmer_size,ncluster,title):\n",
    "    print('\\n', title, ' (KMER =', kmer_size, \", CLUSTERS =\", ncluster, \"):\")\n",
    "    for i in range(ncluster):\n",
    "        exon = 0\n",
    "        intron = 0\n",
    "        intergenic = 0\n",
    "        print('\\n', 'CLUSTER ',i + 1,\":\")\n",
    "        for seq, annotation in zip(seq_list,seq_names):\n",
    "            if class_list[seq] == i:\n",
    "                if \"exon\" in annotation:\n",
    "                    exon += 1\n",
    "                if \"intron\" in annotation:\n",
    "                    intron += 1\n",
    "                if \"intergenic\" in annotation:\n",
    "                    intergenic += 1\n",
    "        sum = intergenic + exon + intron\n",
    "        print('\\n','    intergenic =', round(intergenic/sum,2),' (', intergenic, ')')\n",
    "        print('\\n','    intron =', round(intron/sum,2),' (', intron, ')')\n",
    "        print('\\n','    exon =', round(exon/sum,2),' (', exon, ')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_V2(seq_list,seq_names,class_list,kmer_size,ncluster,\"MISMATCH KERNEL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_list, seq_names = parse_fasta(read_fasta(seqspath))\n",
    "ncluster = 5\n",
    "kmer_size = 6\n",
    "maxniter = 2\n",
    "centroids, class_list = kmeans(seqpath, ncluster, kmer_size, maxniter, spectrum_kernel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_V2(seq_list,seq_names,class_list,kmer_size,ncluster,\"MISMATCH KERNEL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printtest(seq_list,seq_names,class_list,kmer_size,ncluster,\"MISMATCH KERNEL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_V2(seq_list,seq_names,class_list,kmer_size,ncluster,title):\n",
    "    file = open(\"KmeansResults.txt\", \"a\")\n",
    "    file.write( '\\n' +title + ' (KMER =' + str(kmer_size) + \", CLUSTERS =\" + str(ncluster) + \"):\\n\")\n",
    "    for i in range(ncluster):\n",
    "        exon = 0\n",
    "        intron = 0\n",
    "        intergenic = 0\n",
    "        file.write('CLUSTER ' + str(i + 1) + \":\\n\")\n",
    "        for seq, annotation in zip(seq_list,seq_names):\n",
    "            if class_list[seq] == i:\n",
    "                if \"exon\" in annotation:\n",
    "                    exon += 1\n",
    "                if \"intron\" in annotation:\n",
    "                    intron += 1\n",
    "                if \"intergenic\" in annotation:\n",
    "                    intergenic += 1\n",
    "        sum = intergenic + exon + intron\n",
    "        file.write('    intergenic =' + str(round(intergenic/sum,2)) + ' (' + str(intergenic) +  ')\\n')\n",
    "        file.write('    intron =' + str(round(intron/sum,2)) + ' (' + str(intron) +  ')\\n')\n",
    "        file.write('    exon =' + str(round(exon/sum,2)) + ' (' + str(exon) +  ')\\n')\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_list, seq_names = parse_fasta(read_fasta(seqpath))\n",
    "centroids = np.random.randint(0, len(seq_list), ncluster)\n",
    "    # initialize class_list\n",
    "class_list = {}\n",
    "seq_kernel_list = []\n",
    "for seq in seq_list:\n",
    "    similarity_list = []\n",
    "    for centroid in centroids:\n",
    "        similarity, seq_spectrum, centroid_spectrum = spectrum_kernel(\n",
    "                seq, seq_list[centroid], kmer_size)\n",
    "        similarity = np.dot(centroid_spectrum,centroid_spectrum) + np.dot(seq_spectrum,seq_spectrum) - 2 * similarity\n",
    "        seq_kernel_list.append(seq_spectrum)\n",
    "        similarity_list.append(similarity)\n",
    "\n",
    "    class_list[seq] = np.argmin(np.array(similarity_list))\n",
    "    # update centroids 1st time\n",
    "centroids = []\n",
    "for i in range(ncluster):\n",
    "    tmp_list = []\n",
    "    for seq, seq_kernel in zip(seq_list, seq_kernel_list):\n",
    "        if class_list[seq] == i:\n",
    "            tmp_list.append(seq_kernel)\n",
    "    \n",
    "    centroids_new.append(np.mean(tmp_list, axis=0))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(kmers_generator(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (256,) and (61878,) not aligned: 256 (dim 0) != 61878 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[129], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m similarity_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m centroid \u001b[38;5;129;01min\u001b[39;00m centroids_new:\n\u001b[0;32m----> 6\u001b[0m     similarity \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq_kernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcentroid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     similarity \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(centroid_spectrum,centroid_spectrum) \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(seq_spectrum,seq_spectrum) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m similarity\n\u001b[1;32m      8\u001b[0m     similarity_list\u001b[38;5;241m.\u001b[39mappend(similarity)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (256,) and (61878,) not aligned: 256 (dim 0) != 61878 (dim 0)"
     ]
    }
   ],
   "source": [
    "for i in range(maxniter):\n",
    "        # update class_list\n",
    "    for seq, seq_kernel in zip(seq_list, seq_kernel_list):\n",
    "        similarity_list = []\n",
    "        for centroid in centroids_new:\n",
    "            similarity = np.dot(seq_kernel, centroid)\n",
    "            similarity = np.dot(centroid_spectrum,centroid_spectrum) + np.dot(seq_spectrum,seq_spectrum) - 2 * similarity\n",
    "            similarity_list.append(similarity)\n",
    "        class_list[seq] = np.argmin(np.array(similarity_list))\n",
    "    if class_list == old_class_list:\n",
    "        break\n",
    "    old_class_list = class_list.copy()\n",
    "        # update centroids\n",
    "    centroids_new = []\n",
    "    for i in range(ncluster):\n",
    "        tmp_list = []\n",
    "        for seq, seq_kernel in zip(seq_list, seq_kernel_list):\n",
    "            if class_list[seq] == i:\n",
    "                tmp_list.append(seq_kernel)\n",
    "        centroids_new.append(np.mean(tmp_list, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GA': 11,\n",
       " 'AG': 17,\n",
       " 'GT': 11,\n",
       " 'TA': 41,\n",
       " 'AA': 55,\n",
       " 'AT': 43,\n",
       " 'TT': 34,\n",
       " 'AC': 15,\n",
       " 'CT': 11,\n",
       " 'TC': 15,\n",
       " 'TG': 9,\n",
       " 'CA': 23,\n",
       " 'CC': 9,\n",
       " 'GC': 5}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_kmers(seq_list[1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8690,\n",
       " [55, 15, 17, 43, 23, 9, 0, 11, 11, 5, 0, 11, 41, 15, 9, 34],\n",
       " [59, 12, 11, 34, 24, 9, 2, 10, 13, 7, 9, 14, 20, 16, 21, 38])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectrum_kernel(seq_list[1], seq_list[2], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "727b02dba730469f64258a4dd9f7312a3f331a941bc4f1ddf2e0ec5a658cb2e2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
